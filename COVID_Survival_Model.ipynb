{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1446ff0a",
      "metadata": {
        "id": "1446ff0a"
      },
      "source": [
        "# Survival Modeling on COVID-19 ICU Data\n",
        "**Comparison of Cox Proportional Hazards (CoxPH), Random Survival Forest (RSF), and DeepSurv**\n",
        "\n",
        "This notebook demonstrates survival prediction on a simulated ICU dataset using three models:\n",
        "- CoxPH (traditional proportional hazards model)\n",
        "- RSF (tree-based survival model)\n",
        "- DeepSurv (neural network-based Cox model)\n",
        "\n",
        "This is a dataset of patients suffering covid-19 that have been admitted to hospitals in 2 years.\n",
        "\n",
        "The dataset contains data from patients admitted in different hospitals diagnosed with COVID-19 (age, sex, days in hospital, days in ICU, exitus, destination after being admitted in ER, and some medical parameters collected when they were firstly admitted in ER: temperature, heart rate, blood glucose, O2 saturation, systolic blood pressure, and diastolic blood pressure). For more information, look at [Covid-19 ICU Data](https://github.com/jmdu99/Data-Processes-assignment).\n",
        "\n",
        "\n",
        "- age : Age of the patient (in years)\n",
        "- sex : Sex of the patient ('0' if female or '1' if male)\n",
        "- days_hospital : Number of days the patient has been in the hospital (enter '0' if the patient has not been there any day)\n",
        "- days_icu : Number of days the patient has been in ICU (enter '0' if the patient has not been there any day)\n",
        "- temp : Patient temperature (in Celsius degrees)\n",
        "- heart_rate : Patient heart rate (number of beats per minute)\n",
        "- sat_O2 : Patient blood oxygen level (percentage, from '0' to '100')\n",
        "- blood_pres_sys : Patient systolic blood pressure (in mm Hg)\n",
        "- blood_pres_dias : Patient diastolic blood pressure (in mm Hg)\n",
        "- EXITUS: Stutus of patient ( 'Yes' if dies, 'No' if survived the hospitalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "075a031d",
      "metadata": {
        "id": "075a031d"
      },
      "outputs": [],
      "source": [
        "!pip install pycox torchtuples lifelines scikit-survival --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "1QA0Aw6rSLQd"
      },
      "id": "1QA0Aw6rSLQd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "# Automatically detect and load the uploaded file\n",
        "filename = list(uploaded.keys())[0]  # Gets the uploaded filename\n"
      ],
      "metadata": {
        "id": "3h334RgISSQo"
      },
      "id": "3h334RgISSQo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))# Properly decode it"
      ],
      "metadata": {
        "id": "dmSDcw9hnSV4"
      },
      "id": "dmSDcw9hnSV4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/COVID19_data.csv')  # Adjust path if needed\n",
        "df['event'] = df['EXITUS'].map({'YES': 1, 'NO': 0})\n",
        "df['duration'] = df['DAYS_HOSPITAL']\n",
        "\n",
        "features = ['AGE', 'HEART_RATE', 'GLUCOSE', 'SAT_O2', 'BLOOD_PRES_SYS']\n",
        "df_model = df[features + ['duration', 'event']].dropna()"
      ],
      "metadata": {
        "id": "sLhF-JF4eoVz"
      },
      "id": "sLhF-JF4eoVz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pycox.models import CoxPH\n",
        "import torchtuples as tt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
        "\n",
        "\n",
        "# Filter and encode target: duration = DAYS_HOSPITAL, event = EXITUS\n",
        "df = df.dropna(subset=[\"DAYS_HOSPITAL\", \"EXITUS\"])\n",
        "df['EXITUS'] = df['EXITUS'].map({'YES': 1, 'NO': 0})\n",
        "\n",
        "# Define features and target\n",
        "features = ['AGE', 'TEMP', 'HEART_RATE', 'GLUCOSE', 'SAT_O2']\n",
        "X = df[features].fillna(0)\n",
        "y = df[[\"DAYS_HOSPITAL\", \"EXITUS\"]].values\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize input\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train).astype('float32')\n",
        "X_test = scaler.transform(X_test).astype('float32')\n",
        "\n",
        "# Format y as tuple (duration, event)\n",
        "y_train = (y_train_raw[:, 0], y_train_raw[:, 1])\n",
        "y_test = (y_test_raw[:, 0], y_test_raw[:, 1])\n",
        "\n",
        "\n",
        "# Define DeepSurv-style network\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_train.shape[1], 32), #Input layer\n",
        "    torch.nn.ReLU(), # Activation function\n",
        "    torch.nn.BatchNorm1d(32), #Normalizes the outputs of the previous layer\n",
        "    torch.nn.Dropout(0.1), # Prevent overfitting\n",
        "    torch.nn.Linear(32, 1) ## Output: log-risk score\n",
        ")\n",
        "\n",
        "\n",
        "# Cox model\n",
        "model = CoxPH(net, tt.optim.Adam)\n",
        "model.optimizer.set_lr(0.01)\n",
        "\n",
        "\n",
        "# Fit\n",
        "log = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=256,\n",
        "    epochs=100,\n",
        "    callbacks=[tt.callbacks.EarlyStopping()],\n",
        "    val_data=(X_test, y_test),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Plot learning curve\n",
        "log.plot()\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "VMmPXuEvxnrO"
      },
      "id": "VMmPXuEvxnrO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Training loss decreases steadily: Indicates that the model is successfully learning from the training data.The loss drops rapidly at first, then gradually flattens — a typical learning curve.\n",
        "\n",
        "- Validation loss decreases at first, then plateaus: Initially, model generalizes well to unseen data. But after ~5–10 epochs, the validation loss stops improving and slightly oscillates. This suggests early stopping was effective, avoiding overfitting.\n",
        "\n",
        "- No major overfitting:\n",
        "\n",
        "If val_loss had started increasing while train_loss kept dropping, it would indicate overfitting. Here, both losses plateau around similar values — indicating a balanced model."
      ],
      "metadata": {
        "id": "qjoA4GIDSFLp"
      },
      "id": "qjoA4GIDSFLp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning for DeepSurv using Grid Search"
      ],
      "metadata": {
        "id": "rE42aEiNTKDt"
      },
      "id": "rE42aEiNTKDt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DeepSurv model builder\n",
        "def build_model(input_dim, hidden_size=32, dropout=0.2):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Linear(input_dim, hidden_size),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.BatchNorm1d(hidden_size),\n",
        "        torch.nn.Dropout(dropout),\n",
        "        torch.nn.Linear(hidden_size, 1)\n",
        "    )\n",
        "\n",
        "# Hyperparameter tuning loop\n",
        "hidden_sizes = [16, 32, 64]\n",
        "learning_rates = [0.01, 0.001]\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for h in hidden_sizes:\n",
        "    for lr in learning_rates:\n",
        "        print(f\"\\nTraining DeepSurv: hidden_size={h}, lr={lr}\")\n",
        "        net = build_model(X_train.shape[1], hidden_size=h)\n",
        "        model = CoxPH(net, tt.optim.Adam)\n",
        "        model.optimizer.set_lr(lr)\n",
        "        log = model.fit(\n",
        "            X_train, y_train,\n",
        "            batch_size=256,\n",
        "            epochs=100,\n",
        "            val_data=(X_test, y_test),\n",
        "            callbacks=[tt.callbacks.EarlyStopping()],\n",
        "            verbose=False\n",
        "        )\n",
        "        val_loss = log.to_pandas()['val_loss'].dropna().values[-1]\n",
        "        print(f\"Validation loss: {val_loss:.4f}\")\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = model\n",
        "            best_log = log\n",
        "            best_params = (h, lr)\n",
        "\n"
      ],
      "metadata": {
        "id": "MlqN8wp80AGM"
      },
      "id": "MlqN8wp80AGM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training vs validation loss for best model\n",
        "print(f\"\\n✅ Best model: hidden_size={best_params[0]}, lr={best_params[1]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "R6amn8T53pYJ"
      },
      "id": "R6amn8T53pYJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert logger to DataFrame\n",
        "df_log = best_log.to_pandas()\n",
        "\n"
      ],
      "metadata": {
        "id": "fD36tqud4IT0"
      },
      "id": "fD36tqud4IT0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df_log['train_loss'], label='Train Loss')\n",
        "if 'val_loss' in df_log.columns:\n",
        "    plt.plot(df_log['val_loss'].dropna(), label='Validation Loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss (Best DeepSurv Model)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l5_fp5fe4fuS"
      },
      "id": "l5_fp5fe4fuS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluates the DeepSurv survival model we trained using the concordance index (C-index) and visualizes the predicted survival curves for a few patients in the test set."
      ],
      "metadata": {
        "id": "9lg1T9CwP2Oi"
      },
      "id": "9lg1T9CwP2Oi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b70eec",
      "metadata": {
        "id": "37b70eec"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "# Compute baseline hazards before predicting survival\n",
        "model.compute_baseline_hazards()\n",
        "\n",
        "# Predict survival curves for test set\n",
        "surv_deepsurv = model.predict_surv_df(X_test)\n",
        "\n",
        "# Evaluate concordance index (C-index)\n",
        "ev_deepsurv = EvalSurv(surv_deepsurv, y_test[0], y_test[1], censor_surv='km')\n",
        "print(\"C-index (DeepSurv):\", ev_deepsurv.concordance_td())\n",
        "\n",
        "# Plot a few survival curves\n",
        "surv_deepsurv.iloc[:, :5].plot()  # Show survival curves for 5 patients\n",
        "plt.title('Predicted Survival Curves (DeepSurv)')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This visualization supports individual-level clinical decision-making, e.g., Patient 3 may require closer monitoring or earlier intervention.\n",
        "\n",
        "Patient 4 has the best prognosis. The survival probability stays above 0.75 for the entire duration, which suggests low hazard and better expected survival."
      ],
      "metadata": {
        "id": "mR0fUwqmQnvN"
      },
      "id": "mR0fUwqmQnvN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff04bf3c",
      "metadata": {
        "id": "ff04bf3c"
      },
      "outputs": [],
      "source": [
        "from lifelines import CoxPHFitter\n",
        "\n",
        "df_lifelines = df_model.copy()\n",
        "df_lifelines['event'] = df_lifelines['event'].astype(bool)\n",
        "\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(df_lifelines, duration_col='duration', event_col='event')\n",
        "cph.print_summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Interpretation\n",
        "- AGE is the strongest predictor — each year increases mortality risk by ~4%.\n",
        "\n",
        "- Vital signs like heart rate and oxygen saturation are also important but weaker predictors.\n",
        "\n",
        "- GLUCOSE and systolic blood pressure did not show a statistically significant relationship with survival in this dataset."
      ],
      "metadata": {
        "id": "C0JqE9YvTW0U"
      },
      "id": "C0JqE9YvTW0U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c6c30c",
      "metadata": {
        "id": "10c6c30c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sksurv.util import Surv\n",
        "\n",
        "X_rsf = df_model[features]\n",
        "y_rsf = Surv.from_dataframe('event', 'duration', df_model)\n",
        "\n",
        "rsf = RandomSurvivalForest(n_estimators=100, min_samples_split=10,\n",
        "                           min_samples_leaf=15, n_jobs=-1, random_state=42)\n",
        "rsf.fit(X_rsf, y_rsf)\n",
        "\n",
        "# Plot survival function for one sample\n",
        "pred_surv_rsf = rsf.predict_survival_function(X_rsf.iloc[:1])\n",
        "for fn in pred_surv_rsf:\n",
        "    plt.step(fn.x, fn.y, where=\"post\")\n",
        "plt.title(\"RSF Survival Function (Sample 0)\")\n",
        "plt.xlabel(\"Days\"); plt.ylabel(\"Survival Probability\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lifelines import CoxPHFitter\n",
        "\n",
        "# Step 1: Prepare training DataFrame\n",
        "train_df = pd.DataFrame(X_train, columns=features)\n",
        "durations_train, events_train = y_train\n",
        "train_df['duration'] = durations_train\n",
        "train_df['event'] = events_train\n",
        "\n",
        "# Step 2: Prepare test DataFrame\n",
        "test_df = pd.DataFrame(X_test, columns=features)\n",
        "durations_test, events_test = y_test\n",
        "test_df['duration'] = durations_test\n",
        "test_df['event'] = events_test\n",
        "\n",
        "# Step 3: Fit CoxPH model\n",
        "cox_model = CoxPHFitter()\n",
        "cox_model.fit(train_df, duration_col='duration', event_col='event')\n",
        "\n",
        "# Step 4: Evaluate using test data\n",
        "cox_cindex = cox_model.score(test_df, scoring_method='concordance_index')\n",
        "print(f\"C-index (CoxPH - lifelines): {cox_cindex:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uPrq8u9d-gUi"
      },
      "id": "uPrq8u9d-gUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "# ✅ Unpack durations and events from tuple\n",
        "durations_train, events_train = y_train\n",
        "durations_test, events_test = y_test\n",
        "\n",
        "# ✅ Construct structured array for scikit-survival\n",
        "y_train_struct = np.array([(bool(e), t) for t, e in zip(durations_train, events_train)],\n",
        "                          dtype=[('event', 'bool'), ('duration', 'f8')])\n",
        "y_test_struct = np.array([(bool(e), t) for t, e in zip(durations_test, events_test)],\n",
        "                         dtype=[('event', 'bool'), ('duration', 'f8')])\n",
        "\n",
        "# ✅ Fit RSF model\n",
        "rsf = RandomSurvivalForest(n_estimators=100, random_state=42)\n",
        "rsf.fit(X_train, y_train_struct)\n",
        "\n",
        "# ✅ Predict and evaluate C-index\n",
        "rsf_pred = rsf.predict(X_test)\n",
        "rsf_cindex = concordance_index_censored(y_test_struct['event'], y_test_struct['duration'], rsf_pred)[0]\n",
        "print(f\"C-index (Random Survival Forest): {rsf_cindex:.4f}\")\n"
      ],
      "metadata": {
        "id": "v8PDDpnDFEyW"
      },
      "id": "v8PDDpnDFEyW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pycox.models import CoxPH as DeepSurv\n",
        "import torchtuples as tt\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "# Format inputs for DeepSurv\n",
        "X_train_t = X_train.astype('float32')\n",
        "X_test_t = X_test.astype('float32')\n",
        "durations_train, events_train = y_train\n",
        "durations_test, events_test = y_test\n",
        "\n",
        "y_train_tuple = (durations_train, events_train)\n",
        "y_test_tuple = (durations_test, events_test)\n",
        "\n",
        "# Define DeepSurv network\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_train.shape[1], 32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.BatchNorm1d(32),\n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.Linear(32, 1)\n",
        ")\n",
        "\n",
        "deepsurv = DeepSurv(net, tt.optim.Adam)\n",
        "deepsurv.optimizer.set_lr(0.01)\n",
        "\n",
        "# Fit the model\n",
        "deepsurv.fit(X_train_t, y_train_tuple, epochs=100, batch_size=128,\n",
        "             val_data=(X_test_t, y_test_tuple),\n",
        "             callbacks=[tt.callbacks.EarlyStopping()], verbose=False)\n",
        "\n",
        "# Predict survival function\n",
        "deepsurv.compute_baseline_hazards()\n",
        "surv_df = deepsurv.predict_surv_df(X_test_t)\n",
        "\n",
        "# Evaluate\n",
        "ev = EvalSurv(surv_df, durations_test, events_test, censor_surv='km')\n",
        "deepsurv_cindex = ev.concordance_td()\n",
        "\n",
        "print(f\"C-index (DeepSurv): {deepsurv_cindex:.4f}\")\n"
      ],
      "metadata": {
        "id": "OnEIOSPpFqo0"
      },
      "id": "OnEIOSPpFqo0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['CoxPH (Lifelines)', 'Random Survival Forest', 'DeepSurv (NN)'],\n",
        "    'C-Index': [cox_cindex, rsf_cindex, deepsurv_cindex]\n",
        "})\n",
        "\n",
        "sns.barplot(data=results, x='Model', y='C-Index')\n",
        "plt.title(\"Survival Model Comparison (C-Index)\")\n",
        "plt.ylim(0.5, 1)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "rCCqnv9LG1YB"
      },
      "id": "rCCqnv9LG1YB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "276abbd0",
      "metadata": {
        "id": "276abbd0"
      },
      "source": [
        "## 🔍 Comparison\n",
        "- **DeepSurv** captures non-linear feature interactions and outperformed CoxPH if data complexity is high.\n",
        "- **CoxPH** is interpretable and performs well under proportional hazards assumption.\n",
        "- **RSF** handles non-linearity and variable importance naturally, useful for exploratory modeling.\n",
        "\n",
        "# Summary:\n",
        "While all three models demonstrate strong predictive ability, DeepSurv slightly outperforms the others, suggesting that deep learning may offer advantages in capturing complex relationships in survival data—especially when large data and nonlinear effects are present. However, model interpretability and clinical applicability should also be considered when choosing the final model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance (Random Survival Forest)"
      ],
      "metadata": {
        "id": "K3vKpSdAH5k9"
      },
      "id": "K3vKpSdAH5k9"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "# Define a scoring wrapper compatible with permutation_importance\n",
        "def rsf_scorer(model, X, y_struct):\n",
        "    pred = model.predict(X)\n",
        "    return concordance_index_censored(y_struct['event'], y_struct['duration'], pred)[0]\n",
        "\n",
        "# Wrap the scorer to make it compatible with sklearn\n",
        "class RSFWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    def fit(self, X, y):\n",
        "        pass  # Not used\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "rsf_wrapper = RSFWrapper(rsf)\n",
        "\n",
        "# Run permutation importance\n",
        "perm = permutation_importance(\n",
        "    estimator=rsf_wrapper,\n",
        "    X=X_test,\n",
        "    y=y_test_struct,\n",
        "    scoring=lambda model, X, y: rsf_scorer(rsf, X, y),\n",
        "    n_repeats=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Plot results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sorted_idx = perm.importances_mean.argsort()[::-1]\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(np.array(features)[sorted_idx], perm.importances_mean[sorted_idx])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Permutation Feature Importance (Random Survival Forest)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "orsJDeDNH3Am"
      },
      "id": "orsJDeDNH3Am",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance (DeepSurv)\n",
        "\n",
        "While DeepSurv is a neural net (black-box), you can approximate feature importance using Permutation Importance:"
      ],
      "metadata": {
        "id": "ba0lkllfITB_"
      },
      "id": "ba0lkllfITB_"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "# Define a risk function from DeepSurv\n",
        "def predict_risk(X):\n",
        "    surv_df = deepsurv.predict_surv_df(X.astype('float32'))\n",
        "    return -surv_df.mean(axis=0).values  # Higher = riskier\n",
        "\n",
        "# Custom scoring function\n",
        "def deepsurv_scorer(model, X, y):\n",
        "    pred_risk = predict_risk(X)\n",
        "    return concordance_index_censored(y['event'], y['duration'], pred_risk)[0]\n",
        "\n",
        "# Wrap DeepSurv in a dummy estimator class\n",
        "class DeepSurvWrapper:\n",
        "    def fit(self, X, y):\n",
        "        pass  # not needed\n",
        "    def predict(self, X):\n",
        "        return predict_risk(X)\n",
        "\n",
        "# Perform permutation importance\n",
        "perm = permutation_importance(\n",
        "    estimator=DeepSurvWrapper(),\n",
        "    X=X_test,\n",
        "    y=y_test_struct,\n",
        "    scoring=lambda est, X, y: deepsurv_scorer(deepsurv, X, y),\n",
        "    n_repeats=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sorted_idx = perm.importances_mean.argsort()[::-1]\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(np.array(features)[sorted_idx], perm.importances_mean[sorted_idx])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Permutation Feature Importance - DeepSurv\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "nRckw76YITl_"
      },
      "id": "nRckw76YITl_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0  # index of the individual\n",
        "\n",
        "# DeepSurv prediction\n",
        "surv_ds = deepsurv.predict_surv_df(X_test[i:i+1].astype('float32'))\n",
        "\n",
        "# RSF prediction\n",
        "rsf_pred_func = rsf.predict_survival_function(X_test[i:i+1], return_array=False)\n",
        "rsf_time = rsf_pred_func[0].x\n",
        "rsf_prob = rsf_pred_func[0].y\n",
        "\n",
        "# CoxPH prediction (lifelines)\n",
        "cox_surv = cox_model.predict_survival_function(test_df.iloc[i:i+1])\n",
        "\n",
        "# Plot all\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(surv_ds.index, surv_ds.values.flatten(), label='DeepSurv')\n",
        "plt.step(rsf_time, rsf_prob, where=\"post\", label='RSF')\n",
        "plt.plot(cox_surv.index, cox_surv.values.flatten(), label='CoxPH (Lifelines)')\n",
        "\n",
        "plt.title('Survival Function for Individual Patient')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "My7xIyjDIszm"
      },
      "id": "My7xIyjDIszm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At Time = 0:\n",
        "\n",
        "All models (DeepSurv, CoxPH, RSF) predict a survival probability of ~1.0.\n",
        "\n",
        "✅ Interpretation: The patient is alive at the starting point; all models are consistent.\n",
        "\n",
        "From 0 to 20 Days:\n",
        "\n",
        "DeepSurv and CoxPH curves decline steeply, indicating rapid increase in estimated mortality risk.\n",
        "\n",
        "RSF shows a more moderate decline.\n",
        "\n",
        " Interpretation: DeepSurv and CoxPH flag high short-term risk; RSF is more cautious in early predictions.\n",
        "\n",
        "From 20 to 60 Days:\n",
        "\n",
        "CoxPH and DeepSurv continue to predict decreasing survival, approaching zero.\n",
        "\n",
        "Interpretation: These models expect the patient is very likely to die before day 40–60.\n",
        "\n",
        "After 60 Days:\n",
        "\n",
        "RSF curve plateaus at around 0.55 survival probability.\n",
        "\n",
        "Interpretation: RSF suggests a 55% chance of long-term survival — it’s less pessimistic than the other two models.\n",
        "\n",
        "If short-term accuracy is critical (e.g., ICU triage), DeepSurv or CoxPH may provide more precise estimates.\n",
        "\n",
        "If longer-term stratification or handling nonlinear effects is important, RSF can complement the analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "BN3HOeTOJbNm"
      },
      "id": "BN3HOeTOJbNm"
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Ensure you have your feature names\n",
        "features = list(df_model.columns.drop(['duration', 'event']))  # adjust if needed\n",
        "\n",
        "# Step 2: Convert X_test to a DataFrame\n",
        "X_test_df = pd.DataFrame(X_test, columns=features)\n",
        "\n",
        "# Step 3: Take a small sample to speed up SHAP (kernel explainer is slow!)\n",
        "X_sample = X_test_df.sample(n=100, random_state=42)\n",
        "\n",
        "# Step 4: Define a prediction function compatible with SHAP\n",
        "def predict_risk(X):\n",
        "    surv_df = deepsurv.predict_surv_df(X.astype('float32'))\n",
        "    return -surv_df.mean(axis=0).values  # Higher risk = lower survival\n",
        "\n",
        "# Step 5: Run SHAP explanation\n",
        "explainer = shap.KernelExplainer(predict_risk, X_sample)\n",
        "shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "# Step 6: Visualize global feature importance\n",
        "shap.summary_plot(shap_values, X_sample, feature_names=features)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lN0rifkTKAJd"
      },
      "id": "lN0rifkTKAJd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This SHAP summary plot visualizes the impact of individual features on the predicted risk of death from the DeepSurv model (based on ICU COVID-19 data). Each point represents a patient; the x-axis shows the SHAP value — how much that feature contributed to increasing or decreasing the predicted risk. Positive SHAP values (right side) increase risk (lower survival), while negative values decrease risk.\n",
        "\n",
        "AGE is the most influential predictor. High AGE values (pink) consistently push the prediction toward higher risk, whereas lower AGE (blue) values reduce risk — indicating older age is strongly associated with higher mortality.\n",
        "\n",
        "SAT_O2 (oxygen saturation) shows that low oxygen levels (blue) substantially increase risk, as expected in critical COVID-19 cases.\n",
        "\n",
        "HEART_RATE and BLOOD_PRES_SYS (systolic blood pressure) have moderate effects. Both high and low values slightly shift risk, but the influence is weaker and more centered around zero, suggesting mixed or patient-specific impact.\n",
        "\n",
        "GLUCOSE appears to have the smallest contribution among these top five features, though low glucose values (blue) may slightly increase risk in some patients.\n",
        "\n",
        "Overall, the plot demonstrates that the model places the strongest predictive weight on AGE and oxygen levels, both of which align with known clinical risk factors in ICU triage settings."
      ],
      "metadata": {
        "id": "dfpVkcA9NhQ5"
      },
      "id": "dfpVkcA9NhQ5"
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "\n",
        "# Convert X_test to DataFrame if it's a NumPy array\n",
        "X_test_df = pd.DataFrame(X_test, columns=features)\n",
        "\n",
        "# Sample to reduce computation\n",
        "X_sample = X_test_df.sample(n=100, random_state=42)\n",
        "\n",
        "# Define a surrogate regressor to explain risk scores (lower survival probability → higher risk)\n",
        "def rsf_risk_predictor(X_input):\n",
        "    # Predict survival function and compute risk as 1 - survival prob at a fixed time\n",
        "    surv_funcs = rsf.predict_survival_function(X_input, return_array=True)\n",
        "    risk_scores = 1 - surv_funcs[:, 20]  # pick day 20 arbitrarily as a reference point\n",
        "    return risk_scores\n",
        "\n",
        "# SHAP with TreeExplainer\n",
        "explainer_rsf = shap.Explainer(rsf.predict, X_sample)  # Alternative: use rsf_risk_predictor\n",
        "shap_values_rsf = explainer_rsf(X_sample)\n",
        "\n",
        "# Plot SHAP summary\n",
        "shap.summary_plot(shap_values_rsf.values, X_sample, feature_names=features)\n"
      ],
      "metadata": {
        "id": "i_j8UamXNjV6"
      },
      "id": "i_j8UamXNjV6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP Summary Interpretation for RSF Model (COVID-19 ICU Triage)\n",
        "AGE\n",
        "\n",
        "High AGE is strongly increases predicted risk of death (rightward SHAP values).\n",
        "Low AGE is associated with reduced predicted risk (leftward shift).\n",
        "This is the most influential feature in the model, consistent with known clinical risk factors.\n",
        "\n",
        "Low SAT_O2 (e.g., below 90%) increases risk significantly. High SAT_O2 reduces risk; most red dots cluster left of center. Clear inverse relationship with survival — medically logical.\n",
        "\n",
        "High heart rate mild to moderate risk increase.\n",
        "Lower heart rate associated with lower predicted risk.\n",
        "Variability in impact suggests possible interaction effects.\n",
        "\n",
        "Low systolic pressure consistently increases risk (points rightward).\n",
        "High systolic pressure slight reduction or neutral impact.\n",
        "Suggests hypotension is a stronger indicator of poor prognosis than hypertension.\n",
        "\n",
        "Very low glucose slight increase in risk. High glucose impact varies; less consistent signal.Least influential feature overall based on narrow SHAP spread."
      ],
      "metadata": {
        "id": "zvMHa9_xOLVs"
      },
      "id": "zvMHa9_xOLVs"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}